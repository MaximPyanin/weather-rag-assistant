# RAG-Weather-Assistant

**This project is a RAG micro-service designed to provide real-time weather information using advanced AI techniques, including Azure OpenAI models,Langchain orchestration  and Weaviate vector storage.**

## ğŸ“– Overview

<p align="center">
  <!-- Python -->
  <a href="#">
    <img src="https://img.shields.io/badge/Python-3.11-blue?logo=python" alt="Python 3.11">
  </a>
  <!-- LangChain -->
  <a href="#">
    <img src="https://img.shields.io/badge/LangChain-0.3.x-346CA5?logo=langchain" alt="LangChain">
  </a>
  <!-- Weaviate (Vector DB) -->
  <a href="https://weaviate.io/" target="_blank">
    <img src="https://img.shields.io/badge/Vector DB-Weaviate-FF6F00?logo=weaviate&logoColor=white" alt="Weaviate Vector DB">
  </a>
  <!-- ChatGPT / OpenAI -->
  <a href="https://openai.com/" target="_blank">
    <img src="https://img.shields.io/badge/ChatGPT-74aa9c?logo=openai&logoColor=white" alt="ChatGPT (OpenAI)">
  </a>
  <!-- Microsoft Azure -->
  <a href="https://azure.microsoft.com/" target="_blank">
    <img src="https://custom-icon-badges.demolab.com/badge/Microsoft%20Azure-0089D6?logo=msazure&logoColor=white" alt="Microsoft Azure">
  </a>
  <!-- Flask -->
  <a href="https://flask.palletsprojects.com/" target="_blank">
    <img src="https://img.shields.io/badge/Framework-Flask%203.1-orange?logo=flask" alt="Flask 3.1">
  </a>
</p>


---

## âœ¨ Features

- Openai GPT model for generative responses
- Openai embedding model for vector embeddings
- Clean architecture with typed LangChain layers
- ğŸ—ï¸ Integration with Azure OpenAI model deployment and Weaviate vector database
- ğŸ Flask-based backend with Swagger UI
- Docker and Docker Compose for infrastructure management

---

## ğŸ“ Project Hierarchy
The project structure follows a clean, modular approach:
```plaintext
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                # RESTful API and Swagger documentation
â”‚   â”œâ”€â”€ adapters/           # Integration layer with external services (e.g., Weaviate)
â”‚   â”œâ”€â”€ controllers/        # Orchestration layer, managing request handling and response
â”‚   â”œâ”€â”€ embeddings_providers/ # Language models and embeddings services (Azure-based)
â”‚   â”œâ”€â”€ llm_providers/      # Language model wrappers for seamless integration
â”‚   â”œâ”€â”€ services/           # Core business logic, including data indexing and QA systems
â”‚   â”œâ”€â”€ config/             # Configuration management for runtime settings
â”‚   â””â”€â”€ prompts/            # Predefined prompt templates for consistent LLM interactions
â”œâ”€â”€ Dockerfile              # Docker configuration for containerized deployment
â”œâ”€â”€ docker-compose.yml      # Local development environment setup (API + Weaviate)
```

---

## ğŸš€ Quick Start 

```bash
# 1 â€“ clone
git clone https://github.com/MaximPyanin/rag-weather-assistant.git
cd rag-weather-assistant

# 2 â€“ create .env (fill Azure creds)
cp .env.sample .env
# AZURE_OPENAI_ENDPOINT=https://<resource>.openai.azure.com/
# AZURE_OPENAI_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
# AZURE_OPENAI_EMBEDDING_ENDPOINT=https://<resource>.openai.azure.com/

# 3 â€“ build & run
docker compose up -d --build

# 4 â€“ open docs
open http://localhost:5000/swagger/

# 5 â€“ sample request
curl -X POST http://localhost:5000/api/v1/ask \
     -H "Content-Type: application/json" \
     -d '{"query": "What is the temperature in Madrid?"}'
```

---

## ğŸ”§ Configuration
You can configure the application using environment variables. The following variables are required:
```plaintext
AZURE_OPENAI_ENDPOINT -	Base URL of your Azure OpenAI resource
AZURE_OPENAI_KEY - Secret key or leave empty â†  Managed Identity token
AZURE_OPENAI_LLM_DEPLOYMENT - GPT deployment (default gpt-35-turbo)
AZURE_OPENAI_EMBEDDING_ENDPOINT - Same resource or separate embeddings endpoint
AZURE_OPENAI_EMBEDDING_DEPLOYMENT - Embedding deployment (default text-embedding-ada-002)
```
***Any value in AppConfig can be overridden via .env***

## ğŸ“œ LICENSE
This project is licensed under the MIT License. See the [LICENSE](LICENSE) file for details.